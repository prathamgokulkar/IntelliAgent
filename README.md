IntelliAgent AI: A Multi-Agent RAG System
A full-stack, AI-powered application for conversing with your financial documents. This system uses a multi-agent architecture to provide intelligent, fact-checked answers from both digital and scanned PDFs.

Features
ğŸ“„ Hybrid PDF Processing: Handles both digitally native and scanned (image-based) PDFs seamlessly.

ğŸ§  Multi-Agent Architecture: A robust backend built with specialized agents for Orchestration, Indexing, OCR, and Q&A.

ğŸ” Conversational Q&A: Ask complex questions in natural language and get answers based on the document's content.

âœ… Fact-Checked Responses: Includes a Validation Agent to check the AI's answers against the source text, reducing hallucinations.

ğŸ³ Persistent Memory: Utilizes a Qdrant vector database running in Docker for fast, reliable, and isolated document memory.

ğŸ¨ Modern UI: A sleek, responsive chat interface built with React and Tailwind CSS.

âš¡ Fast Inference: Powered by the high-speed Groq API for near-instantaneous LLM responses.

Architecture
Frontend: React + Vite (Port 5173)

Backend: Python + FastAPI (Port 8000)

AI Orchestration: LangChain

Vector Database: Qdrant (via Docker)

Embedding Model: Hugging Face all-MiniLM-L6-v2

Language Model (LLM): Groq API (Llama 3)

OCR Engine: Tesseract OCR

PDF Parsing: PyMuPDF

Quick Start
Prerequisites
Docker Desktop: Must be installed and running.

Python 3.10+ and a virtual environment (e.g., conda).

Node.js and npm.

Tesseract OCR installed on your system.

1. Configure Environment Variables
In the backend/ directory, create a .env file and add your Groq API key:

GROQ_API_KEY="gsk_YourSecretKeyHere"

2. Start the Qdrant Database
In a terminal, navigate to the backend/ directory and run:

docker-compose up -d

You can view the Qdrant dashboard at http://localhost:6334/dashboard.

3. Start the Backend Server
In a new terminal, activate your Python environment, navigate to the backend/ directory, and run:

# Activate your conda environment (e.g., conda activate btech_final)
pip install -r requirements.txt
uvicorn main:app --reload

The backend will be running on http://localhost:8000.

4. Start the Frontend Server
In a third terminal, navigate to the frontend/ directory and run:

npm install
npm run dev

The application will be available at http://localhost:5173.

API Endpoints
POST /api/process-invoice: Clears the old session and indexes a new PDF.

POST /api/query: Receives a question and returns an AI-generated answer.

POST /api/clear-store: Manually clears the vector database.

Project Structure
IntelliAgent-AI/
â”œâ”€â”€ frontend/           # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ package.json
â””â”€â”€ backend/            # Python backend
    â”œâ”€â”€ .env
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ main.py         # Orchestrator Agent (FastAPI)
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ src/
        â”œâ”€â”€ agents/     # Specialized agent logic
        â””â”€â”€ core/       # Core services (loader, splitter, etc.)

License
MIT